blogdown::serve_site()
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE,
echo = TRUE, dpi = 300, cache.lazy = FALSE,
tidy = "styler", fig.width = 3, fig.height = 4)
# Modelling AlgorithmsS
library(glmnet) # Glmnet regression
library(ranger) # Random Forests
# Formating, Visualisations and tables
library(scales) # Number formats
library(knitr) # Table
library(gridExtra) # multiplot
library(e1071) # Summary distribution
library(skimr) # Summarise dataframe
library(corrplot) # Correlation plot
library(probably) # Probability thresholds
library(tidymodels)
library(caret)
# Data handling Packages
library(tidyverse) # Data handling/ Graphics
library(data.table) # Data handling
library(plotly)
df_churn <- data.table::fread("C:/Users/LUCBA/Projects/Churn_Modelling.csv")
# Summarise datafrmae
skim(df_churn)
# Convert all names to lower case
df_churn <-
df_churn %>%
set_names(., tolower(names(.))) %>%
select(-c(rownumber, customerid))
theme_set(theme_minimal())
# Visualise the distribution of the data
plotly::ggplotly(
df_churn %>%
select(exited) %>%
mutate(exited = factor(exited, levels = c(0,1), labels = c("Remain", "Churn"))) %>%
group_by(exited) %>%
count() %>%
ungroup() %>%
mutate(p = n / sum(n)) %>%
ggplot(aes(x = exited, y = p)) +
geom_col(fill = "blue") +
scale_y_continuous(labels = scales::percent) +
theme(plot.title = element_text(hjust = 0.5)) +
labs(x = NULL, y = NULL) +
ggtitle("Proportion of Loan Repayments & Default")
)
# Change the variable type from numeric to factor
df_churn <-
df_churn %>%
mutate(exited = factor(exited, levels = c(1,0), labels = c("Churn", "Remain")))
library(patchwork)
# Distribution by Geography
p1 <- plotly::ggplotly(
df_churn %>%
group_by(geography, exited) %>%
count() %>%
ggplot(aes(x = geography, y = n, fill = exited)) +
geom_col(position = "fill") +
scale_y_continuous(labels = scales::percent) +
labs(y = NULL, x = NULL) +
theme(plot.title = element_text(hjust = 0.5),
legend.position = "bottom") +
ggtitle("Geography")
)
# Distribution by Gender
p2 <- plotly::ggplotly(
df_churn %>%
group_by(gender, exited) %>%
count() %>%
ggplot(aes(x = gender, y = n, fill = exited)) +
geom_col(position = "fill") +
scale_y_continuous(labels = scales::percent) +
labs(y = NULL, x = NULL) +
theme(plot.title = element_text(hjust = 0.5),
legend.position = "bottom") +
ggtitle("Gender")
)
subplot(p1, p2, nrows = 1)
# Relationship with Churn and Numerical variables
plotly::ggplotly(
df_churn %>%
{bind_cols(select_if(., is.numeric),
select_at(., "exited"))
} %>%
gather(-exited, key = "var", value = "value") %>%
ggplot(aes(x = exited, y = value, fill = exited)) +
geom_boxplot() +
theme(legend.position = "none") +
facet_wrap(~ var, scales = "free")  +
ggtitle("Numerical Variable Relationship with Churn")
)
# Distribution by Credit Card
p1 <- ggplotly(df_churn %>%
mutate(hascrcard = factor(hascrcard, labels = c("No Card", "Has Card"))) %>%
group_by(hascrcard, exited) %>%
count() %>%
ggplot(aes(x = hascrcard, y = n, fill = exited)) +
geom_col(position = "fill") +
scale_y_continuous(labels = scales::percent) +
labs(y = NULL, x = NULL) +
theme(plot.title = element_text(hjust = 0.5),
legend.position = "bottom") +
ggtitle("Credit Card")
)
# Distribution by isactivemember
p2 <- ggplotly(df_churn %>%
mutate(isactivemember = factor(isactivemember, labels = c("Inactive", "Active"))) %>%
group_by(isactivemember, exited) %>%
count() %>%
ggplot(aes(x = isactivemember, y = n, fill = exited)) +
geom_col(position = "fill") +
scale_y_continuous(labels = scales::percent) +
labs(y = NULL, x = NULL) +
theme(plot.title = element_text(hjust = 0.5),
legend.position = "bottom") +
ggtitle("Active Member")
)
subplot(p1, p2, nrows = 1)
# Create a variable of total family size
corrplot(cor(df_churn %>% select_if(is.numeric)))
# Create an index to split the data
set.seed(1989)
l_split_index <-
initial_split(data = df_churn,
prop = 0.75,
strata = exited
)
# Create training and testing set using the index
df_train <- training(l_split_index)
df_test <- testing(l_split_index)
# Check same distribution of output
bind_rows(
as.data.frame(round(prop.table(table(df_train$exited)),4)) %>% mutate(Data = "Train"),
as.data.frame(round(prop.table(table(df_test$exited)),4)) %>% mutate(Data = "Test")
) %>%
spread(Var1, Freq) %>%
kable(style = "pandoc",
align = c('c','c','c'))
# Preprocessing - With near zero inflation
recipe <-
df_train %>%
recipe(exited ~ .) %>%
step_rm(surname) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_normalize(all_numeric(), -all_outcomes()) %>%
step_corr(all_numeric(), -all_outcomes(), threshold = 0.9) %>%
step_zv(all_predictors()) %>%
step_nzv(all_predictors()) %>%
prep()
# Apply processing to test and training data
df_baked_train <- recipe %>% bake(df_train) # Preprocessed training
df_baked_test <- recipe %>% bake(df_test) # Preprocessed testing
rm(df_train, df_test) # remove old data
# Cross validation
set.seed(1989)
l_cv <- vfold_cv(df_baked_train, v = 5, strata = "exited") # Cross validation
# Get features
logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(exited ~ ., data = df_baked_train) %>%
tidy() %>%
filter(p.value < 0.05) %>%
kable(align = c('c', 'c', 'c', 'c', 'c'))
# glm - 5 fold CV
mod_glm <-
list(parameters = NULL,
df = map2_df(.x = l_cv$splits,
.y = l_cv$id,
function (split = .x, fold = .y)
{
# Split the data into analysis and assessment tables
df_analysis <- analysis(split)
df_assessment <- assessment(split)
# Build the model
mod <-
logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(exited ~ creditscore + age + tenure +
balance + isactivemember +
geography_Germany + gender_Male,
data = df_analysis)
# Summarise Predictions
table <-
tibble(fold = fold,
truth = df_assessment$exited,
.pred_Churn =
predict(mod,
new_data = df_assessment,
type = "prob")[[".pred_Churn"]],
.pred_Remain =
predict(mod,
new_data = df_assessment,
type = "prob")[[".pred_Remain"]],
.pred_Class =
predict(mod,
new_data = df_assessment) %>%
unlist() %>%
as.character()
) %>%
mutate(.pred_Class = factor(.pred_Class))
})
)
# Set the model engine
mod <-
logistic_reg(mode = "classification",
penalty = tune(),
mixture = tune()) %>%
set_engine("glmnet")
# Build initial model with varying parameters and cross validation
set.seed(1989)
mod_results_tbl <-
tune_grid(
formula   = exited ~ .,
model     = mod,
resamples = l_cv,
grid      = grid_max_entropy(parameters(penalty(),
mixture()),
size = 50),
metrics   = metric_set(roc_auc),
control   = control_grid(verbose = FALSE)
)
# Store the parameters
df_parameter <- mod_results_tbl %>% select_best("roc_auc")
# glmnet - 5 fold CV
mod_glmnet <-
list(parameters = df_parameter,
df = map2_df(.x = l_cv$splits, # Add predictions and find c
.y = l_cv$id,
function (split = .x, fold = .y)
{
# Split the data into analysis and assessment tables
df_analysis <- analysis(split)
df_assessment <- assessment(split)
# Build the model
mod_2 <-
logistic_reg(mode = "classification",
penalty =
as.numeric(df_parameter["penalty"]),
mixture =
as.numeric(df_parameter["mixture"])
) %>%
set_engine("glmnet") %>%
fit(exited ~ ., data = df_analysis)
# Summarise Predictions
table <-
tibble(fold = fold,
truth = df_assessment$exited,
.pred_Churn =
predict(mod_2,
new_data = df_assessment,
type = "prob")[[".pred_Churn"]],
.pred_Remain =
predict(mod_2,
new_data = df_assessment,
type = "prob")[[".pred_Remain"]],
.pred_Class =
predict(mod_2, new_data = df_assessment) %>%
unlist() %>%
as.character()
) %>%
mutate(.pred_Class = factor(.pred_Class))
})
)
rm(mod, mod_results_tbl, df_parameter) # Clear memory
# Set the model engine
mod <-
rand_forest(mode = "classification",
mtry = tune(),
trees = tune(),
min_n = tune()) %>%
set_engine("ranger")
# Build initial model with varying parameters and cross validation
set.seed(1989)
mod_results_tbl <-
tune_grid(
formula   = exited ~ .,
model     = mod,
resamples = l_cv,
grid      = grid_random(parameters(mtry(c(1, 22)),
trees(),
min_n()),
size = 50),
metrics   = metric_set(roc_auc),
control   = control_grid()
)
blogdown::serve_site()
blogdown::stop_server()
blogdown::hugo_server()
blogdown::install_hugo()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
