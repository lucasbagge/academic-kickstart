---
title: XGBoost med Tidymodels
author: Lucas Bagge
date: '2020-05-22'
slug: xgboost-med-tidymodels
categories:
  - tidymodels
  - xgboost
tags:
  - xgboost
subtitle: 'XGBoost i tidymodels'
summary: 'Tidymodels værktøjet er en fantastiak bidrag til modellering. I denne post vil jeg tage et volleyball data og
finde ud af gennem en avanceret XGBoost klassificeringsmodel, om vi kan forudsige hvem der vil vinde.'
authors: []
lastmod: '2020-05-22T14:42:57+02:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, 
                      echo = TRUE, dpi = 300, cache.lazy = FALSE,
                      tidy = "styler", fig.width = 8, fig.height = 5)
library(tidymodels)
library(skimr)
library(tibble)
library(dplyr)
library(tidyr)
library(magrittr)
library(tidyquant)
theme_set(theme_minimal())
```

## Explore data

Målet for dette opslag er at forudsige om et beach volleyball vil vinde 
baseret på deres *game play stat*; errors, blocks, attacks. etc. Da der er er meget data, kan
vi benytte os af en mere avanceret machine larning model **XGBoost**. En af de ting som
er krævende ved denne model er den har en masse parameter, som  kræver tuning. 


```{r}
vb_matches <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-19/vb_matches.csv', guess_max = 76000)

vb_matches 
```

Data indeholder *match stat* som; error, kills etc.. De oplysninger skal vi bruge i vores model. For at finde frem til det 
kræves der noget feature engineering, hvor vi skal beregne vinder og taber. 
Der er nogle `NA` værdier som vi undlader at medtage i vores data.

```{r}
vb_parsed <- vb_matches %>% 
  transmute(
    circuit,
    gender,
    year,
    # vil to hold team med større sandynlihghed veinde for nogle fejl eller sttacks
    w_attacks = w_p1_tot_attacks + w_p2_tot_attacks,
    w_kills = w_p1_tot_kills + w_p2_tot_kills,
    w_errors = w_p1_tot_errors + w_p2_tot_errors,
    w_aces = w_p1_tot_aces + w_p2_tot_aces,
    w_serve_errors = w_p1_tot_serve_errors + w_p2_tot_serve_errors,
    w_blocks = w_p1_tot_blocks + w_p2_tot_blocks,
    w_digs = w_p1_tot_digs + w_p2_tot_digs,
    l_attacks = l_p1_tot_attacks + l_p2_tot_attacks,
    l_kills = l_p1_tot_kills + l_p2_tot_kills,
    l_errors = l_p1_tot_errors + l_p2_tot_errors,
    l_aces = l_p1_tot_aces + l_p2_tot_aces,
    l_serve_errors = l_p1_tot_serve_errors + l_p2_tot_serve_errors,
    l_blocks = l_p1_tot_blocks + l_p2_tot_blocks,
    l_digs = l_p1_tot_digs + l_p2_tot_digs
  ) %>% 
  na.omit()
library(dplyr, warn.conflicts = FALSE)

winner <- vb_parsed %>% 
  select(circuit, gender, year,
         w_attacks:w_digs) %>% 
  rename_all(function(x) gsub("w_", "", x)) %>% 
  mutate(win = "win")

losers <- vb_parsed %>% 
  select(circuit, gender, year,
         l_attacks:l_digs) %>% 
  rename_all(function(x) gsub("l_", "", x)) %>% 
  mutate(win = "lose")

vb_df <- bind_rows(winner,
                   losers) %>% 
  mutate_if(is.character, factor)

vb_df %>%  count(gender)
```

Jeg bygger to dataframe en for vinder og en for taber.

```{r}
vb_df %>% 
  pivot_longer(attacks:digs, names_to = "stat", values_to = "value") %>% 
  ggplot(aes(gender, value, fill = win, color = win)) +
  geom_boxplot(alpha = 0.4) +
  facet_wrap(~ stat, scales = "free_y", nrow = 2) +
  labs(y = NULL, color = NULL, fill = NULL)
```

Vi har delt ud på mænd og kvinder. Der er nogle ting som er meget lig hvad vi ville
forvente. Dog ligner det at serve_error ikke har den store betydning. Error har en stor betydning.

## Byg modellen

Det første vi vil gøre er at splitte vores data op i træning og testing.

```{r}
set.seed(123)
# Split data
vb_split <- initial_split(vb_df, strata = win)
vb_train <- training(vb_split)
vb_test <- testing(vb_split)
```

En fordel (ud over at være en mere præcis model) ved xgboost er den ikke kræver meget
preprocessing, og vi skal ikke bekymre sig om faktor, centering eller skalering af vores data.
Ulempen er vi skal tune mange parameter. 

```{r}
xgb_spec <- boost_tree(
  # skal håndtere en masse model parameter vi skal tune
  # vi tuner ikke træet men sørger for der er nok af dem.
  trees = 1000,
  # hyper parameter
  # de handler om model kompleksitet. 
  tree_depth = tune(), min_n = tune(), loss_reduction = tune(),
  sample = tune(), mtry = tune(),
  learn_rate = tune()
) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

xgb_spec
```

Nu er det sat op, men vi skal sætte mulige parameter. Her vil jeg bruge et `space-filling` design så vi kan
afdække hyperparameterne.

```{r}
xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  # sample størrelsen  er en andel
  sample_size = sample_prop(),
  # har en ukendt, ds vi ved  ikke hvor mange data punkter.
  # 
  finalize(mtry(), vb_train),
  learn_rate(),
  size = 20 
)
xgb_grid
```

Læg mærke til at vi behandler `mtry()` anderledes fordi den afhænger af de faktiske
antal predictors i data. 

Med tidymodels er der kommet den specielle funktion workflow som skaber et dynamik for en. 
Da vi ikke har noget data prepocession så kan vi bruge `àdd_formula()`.

```{r}
xgb_wf <- workflow() %>% 
  add_formula(win~ .) %>% 
  add_model(xgb_spec)
xgb_wf
```

Hernæst laver vi en **cross-validation** resample for at tune vores model. 

```{r}
set.seed(123)

vb_folds <- vfold_cv(vb_train, strata = win)
vb_folds
```

Nu kan vi begynde at tune vores model.

```{r}
doParallel::registerDoParallel()

set.seed(234)
xgb_res <- tune_grid(
  xgb_wf,
  resamples = vb_folds,
  grid = xgb_grid,
  control = control_grid(save_pred = TRUE)
)

xgb_res 
```

## Undersøg resultater

Vi kan undersøge metricerne for alle disse modeller.
```{r}
xgb_res %>% 
  collect_metrics() 
```

Vi kan her se prøcision og real under kurven (ROC).

```{r}
xgb_res %>% 
  collect_metrics() %>% 
  filter(.metric == "roc_auc") %>% 
  select(mean, mtry:sample_size) %>% 
  pivot_longer(mtry:sample_size,
               names_to = "parameter",
               values_to = "value") %>% 
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~ parameter, scales = "free_x")
```

Husk her at vi brugte et **space-filling** design for parameterne. Det ser ud at højere
værdier for træet dybde er bedre, men på den anden side så tager jeg med at der er mange
kombinationer af parameter der er gode og give et præcis resultat. 

```{r}
show_best(xgb_res, "roc_auc")

best_auv <- select_best(xgb_res, "roc_auc")

best_auv 

final_xgb <- finalize_workflow(xgb_wf, best_auv)
final_xgb
```

```{r}
library(vip)

final_xgb %>% 
  fit(data = vb_train) %>% 
pull_workflow_fit() %>% 
  vip(geom = "point")
```

Ud fra plottet ser vi at de vigtigs precidtor for at vinde en kamp er antal kills, errors og attacks.
Køn har ingen betydning.

Nu er det på tide at vende tilbage til vores testing sæt. Her bruger vi `last_fit()` til at fitte vores model
en sidste gang på vores træning data og evaluate vores model en sidste ang på vores testing sæt. 


```{r}
final_res <- last_fit(final_xgb, vb_split)
final_res %>% 
  collect_metrics 
```

Det ligner ikke vi overfitter vores model.

```{r}
final_res %>% 
  collect_predictions() %>% 
  conf_mat(win, .pred_class)
```
 
 Vi kan også lave en **ROC kurve** for vores testing sæt. 
 
```{r}
final_res %>%
  collect_predictions() %>%
  roc_curve(win, .pred_win) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.5, color = "midnightblue") +
  geom_abline(
    lty = 2, alpha = 0.5,
    color = "gray50",
    size = 1.2
  )
```
  
De er forussigelse på testing data. Vi kan se fra vores plot hvordan modellen klare sig.
 
## Apendix

Jeg har leget med et andet plot, som jeg synes er meget spændende.

```{r}
vb_matches %>%
  # put all player countries into one column named "player_country"
  gather(c(w_p1_country, w_p2_country, 
           l_p1_country, l_p2_country),
         key="player", 
         value="player_country") %>%
  # group by the country columns
  group_by(country, player_country)  %>%
  # count number of combos per country:player_country
  count() %>% 
  # clean up variable
  drop_na() %>% ungroup() %>%
  # define scale so the outlier isn't too obnoxious
  mutate(ncolors=cut(n, breaks=c(0,10,25,50,75,100,125,150,175,200,1000,25000,50000,max(n)),
                      labels=c(10,25,50,75,100,125,150,175,200,1000,25000,50000,max(n)))) %>%
  # Plotting
  ggplot(aes(y=reorder(country,-n), 
           x=reorder(player_country,-n),
           size=ncolors, 
           color=ncolors))+
  geom_point(alpha=0.8)+
  scale_colour_viridis_d(option = "plasma") +
  theme(axis.text.x=element_text(angle=90, hjust=1),
        axis.text = element_text(size=8),
        legend.position="right",
        plot.background = element_rect(fill="bisque"),
        legend.background = element_blank(),panel.background = element_blank(),legend.key=element_blank())+
  labs(x="Player countries", y="Match location", 
       color="Number of \ncombinations",size="Number of \ncombinations",
       caption = "Plot by @LucasBagge \n Source: BigTimeStats",
       title = "Where do beach volleyball players come from and where do they play?",
       subtitle = "The most common combo is from the USA, playing in the USA")
```

