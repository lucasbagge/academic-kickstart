---
title: Intro to machine learning
author: Lucas Bagge
date: '2020-05-29'
slug: intro-to-machine-learning
categories:
  - bootstrap
  - k-fold
tags:
  - bootstrap
  - k-fold
subtitle: ''
summary: ''
authors: []
lastmod: '2020-05-29T21:38:25+02:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, 
                      echo = TRUE, dpi = 300, cache.lazy = FALSE,
                      tidy = "styler", fig.width = 8, fig.height = 5)
library(tidymodels)
library(skimr)
library(tibble)
library(dplyr)
library(tidyr)
library(magrittr)
```

## INtroduktion

I denne serie af post vil jeg fokuser på nogle af de
grundlæggende begreber og metoder for Machine Learning.

Her vil jeg gennemgå **resampling metoder**. Vores oprindelig data er et sample, men vi vil gerne resample det for at checke dens kvalitet. Der er to metoder man kan gøre det på;
- Bootstrap.
- Cross-validation. 

Der er forskellige typer fejl man kan have som bestå af **tranings error** og **test error**. Der er forskel i de to typer fejl og hvis man ser dem på en graf vil deres udvikling også være forskellig.

Når vi vil forudsige noget så kan der opstå fejl og det er bias og varians. **Bias** er hvor langt fra er vi fra sandheden. Varians er hvordan estimater bevæger sig omkring sit gennemsnit.  

## Prediction error

Det er som jeg har forklaret bundet i hvordan vores data kan indhoolde eror i dens komponenter, som vi skal håndterer.

## Validation set - approach

Med denne metode deler vi data op i to dele; **trænings sæt** og **validering sæt**. Her skal man fitte modeleln til sit trænignssæt og bruge det til at forudsige observationerne i validering sættet. De error vi får vil være et estimat for test error. Det er altså en opdelingaf vores data og modsat af hvordan man gør cross validation, som jeg kommer til senere. 

Med denne metode kan vi risiker at for meget upræcise test eror fordi modellen kommer til at være meget afhængig af hvad man indsætter som trænings og validering. 

## Cross validation

Denne metode bruges som validation til ast beregne test error. Med disse estimater kan vi finde den bedste model. Ideen er vi deleter data op i K lige store dele. Her efterlader vi delen k, fitter modellen til K-1 og hermed opnår prediction. Der foregår i forskellig trin, så vi starter med et valideingsæt og så skiftes den ud med de sandra sample.  

