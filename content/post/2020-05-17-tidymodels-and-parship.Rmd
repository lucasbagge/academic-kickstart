---
title: Tidymodels, Random Forest og parsnip  
author: Lucas Bagge
date: '2020-05-17'
slug: tidymodels-and-parsnip
categories:
  - logistic regression
  - random forest
  - tidymodels
  - parship
tags:
  - tidymodels
  - ML
  - parship
  - random forest
subtitle: ''
summary: ''
authors: []
lastmod: '2020-05-17T20:19:54+02:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, 
                      echo = TRUE, dpi = 300, cache.lazy = FALSE,
                      tidy = "styler", fig.width = 8, fig.height = 5)
library(tidymodels)
library(skimr)
library(tibble)
library(dplyr)
library(tidyr)
library(magrittr)
```

## Introduktion

Denne post jeg på kigger på to modeller.
Den **logistiske regression** og **random forest**, hvor de begge bliver brugt
som klassifikations modeller.

Jeg kommer til at gennemgå og beskrive random forst da det er en model, 
som er forholdsvis ny for mig og der er nogle teoretiske framwork jeg gerne 
vil prøve at forklare.

Desuden kommer vi til at stifte bekendtskab med `parsnip` som gør det let at 
skifte om til de forskellige modeller. Med det nye framwork fra 
`tidymodels` kan man skifte utrolig let fra `glm` til en **cross validated** 
random forest med `ranger`
med få linjers koder.

## Random forest

Det er en af de mest populære machine learning algoritmer og kan både bruges
som en regresssion og klassifikation model. 

Som navnet antyder så laver algoritmen en skov med forskellige beslutningstræer. 
Desto flere træer desto mere robust er modellen. Navnet random kommer grundet to koncepter

1) Et randomiseret sample af trænings data, når man bygger træet
2) Et randomiseret subsæt af features, når man splitter noder.

Når vi træer hver træ så lærer den fra et random sample af data punkter. 
Samples er trukket med erstatning, som kaldes **bootstrapping**, som betyder 
at et sample vil blive brugt flere gange i et enkelt træ. Ideen er at ved at
træne hver træ med forskellige samples, så vil vi få en lavere varians og 
ikke få et højere bias.

Ens prediction fås ved at tage gennmsnittet af predictor for hver beslutningstræ.
Denne procedure kaldes for **bagging**.

Fordele er man kan bruge den som klassifikation og regression. Den vil ikke overfitte. 
Den kan håndtere store datasæt med mange dimensioner.

Ulemper er den ikke er så god til regressioner. Den er ikke god til at forudsige.
Der er heller ikke meget kontrol over modellen. 

Dog er modellen anvendelig i mange sektor såsom banker, forsikringsselskaber, 
forretninger somkan bruges til at finde de loyolae kunder. Den kan også bruges i
aktiemarkedet til ast finde opførelsen af en aktie. 

## Data

I dette projekt bruger jeg data
fra Telco Customer Churn. Data indeholder 7043 rækker som hver repræsentere en kunde. 
Der er 21 kolonner som er mulige predictor, der giver information til vi kan
forecast opførelse og give indsigt på forebyggelsesprogrammer. 

`Churn` er den afhængige variable og viser om kunden har forladt virksomheden 
indenfor den seneste måned. 

Jeg bruger funnktionen `skim` til at skabe et overblik over mit data.

```{r}
telco <- readr::read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
telco %>% 
  skimr::skim()
```

Her er en række ting at lægge mærke til her.

- **customerID** er en unik id for hver række og af den grund har den ingen
deskriptiv eller predictive power og den skal fjernes.
- Der er meget få manglende værdier, som vi ser ud fra `skim()` kan se kommer fra
TotalCharges. De kan godt slettes.

```{r}
telco <- telco %>% 
  select(-customerID) %>% 
  drop_na()
```

## Modellering med `tidymodels`

Denne post giver også en introduktion til tidymodels. Derfor vil modellen
være simpel og kommer til at bestå af **logistic regression** model uden meget
data bearbejdring.

## Train and test split

`rsample()` kan bruges til at lave en randomiserede træning og test data, 
som selvfølgelig er konstrueret udfra vores orginale telco data.

```{r}
set.seed(1972)

train_test_split <- rsample::initial_split(
  data = telco,
  prop = 0.8
)
train_test_split
```

Ud fra ovenstående har vi at de 7032 kunder er blevet delt ud, og de 5626 er blevet
sat i træningssættet. Vi gemmer dem ned i deres eget data frame;

```{r}
train_tbl <- train_test_split %>% training() %>% 
  unnest()
test_tbl <- train_test_split %>% testing()
```

## En bage opskrift

For at lave en del af arbejde for at bygge modellen bruger vi `recipe()`. Denne
pakke bruger *bage metafor* til at behandle data og foretage diverse præprocessor
såsom, missing values, fjerne predictor, centering og scaling osv..

Det første man gør er at definere `recipe` og de transformationer man vil bruge 
på ens data. Der er ikke meget at gøre i dette tilfælde, udover at tranaformerer
til faktor.


```{r}
recipe_simple <- function(dataset) {
  recipe(Churn ~ ., data = dataset) %>% 
    step_string2factor(all_nominal(), -all_outcomes()) %>% 
    prep(data = dataset)
}
```

For at undgår man vi har en **data lækage** (oveføre information mellem træning 
og test data), skal data være 'prepped' ved 
kun at bruge `train_tbl`.

```{r}
recipe_prepped <- recipe_simple(dataset = train_tbl)
```

Som den sidste del så skal vi *bage opskriften* for at alle præprocessor
bliver inkluderet i data sættene.

```{r}
train_baked <- bake(recipe_prepped, new_data = train_tbl)
test_baked <- bake(recipe_prepped, new_data = test_tbl)
```

## Fit modellen

`Tidymodels` er det helt nye indspark fra tidyverse folkene på at skabe et framwork
for machine learning.
Hertil er der blevet lavet en del justeringer og nye pakker. En central pakke i 
dette framwork er `parsnip`,som skaber en adgang til mange machine learning pakker 
uden man skal kunne syntaksen til dem alle.

Man skal følge tre trin:

1) Bestem **typen af modellen** og **mode**.
2) Bestem **engine**.
3) Bestem model specifikationer og data der skal bruges.

```{r}
logistic_glm <- logistic_reg(mode = "classification") %>% 
  set_engine("glm") %>% 
  fit(Churn ~ .,
      data = train_baked)
```

Som sagt så kan du vælge en masse andre engine. I dette tilfælde hvor vi bruge en
logistisk regression, så kan vi vælge; `glm`, `glmnet`, `stan`, `spark` og `keras`.
Det smarte er vi bare kan skifte det ud og så klare parsnip transitionen.

## Hvor godt klare modellen sig?

Det er væsentlig at se hvor god modellen er og her bruger vi pakken
`yardstick`, som gør det let at beregne forskellige måleværktøjer.
Før man kan beregne disse måle enheder skal vi beregne nogle
predictor ved at bruge `test_baked` til predict funktionen.

```{r}
prediction_glm <- logistic_glm %>% 
  predict(new_data = test_baked) %>%
  bind_cols(test_baked %>%  select(Churn))

head(prediction_glm)
```

Der kan benyttes mange matricer til at undersøge hvor god modellen er,
men fokus for denne post bliver **accuracy**, **precision**, **recall** og **F1_score**.

Disse mål bliver udledt af **Confusion Matrix**, som er en tabel der beskriver
hvor godt en klassifikations model klare sig. Denne matric er i sig selv ikke svære at
forstå, da den angiver antallet af; *false positives*, *false negatives*, *true positives*
og *true negatives*. Dog er nogle af målene, som udledes herfra svære koncepter og kræver
reflektion for at forstå deres betydning.

```{r}
prediction_glm %>% 
  conf_mat(Churn, .pred_class) %>% 
  pluck(1) %>% 
  as_tibble() %>% 
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = "white", alpha = 0.5, size = 12)
```

Modellen **Accuracy** er andel af prediction modellen ramte plet og kan udregnes ved at
lade predictions_glm gå gennem metrics funktionen. Dog er den ikke så troværdig, hvis
ens data er ubalanceret.

```{r}
prediction_glm %>% 
  metrics(Churn, .pred_class) %>% 
  select(-.estimator) %>% 
  filter(.metric == "accuracy")
```

Modellen får altså en score på 78%.

**Precision** målser hvor sensitiv modellen er overfor False Positive, mens
Recall ser hvor sensitiv modellen er for False Negative.

Disse metricer er meget vigtig informationer for virksomheder fordi man så kan
forudsige hvilke kunder der er i en risiko gruppe for at forlade forretningen.
Herfra kan man så benytte sig af en fastholdessstrategi. Desuen kan
man bruge oplysning til ikke at bruge penge på kudner der alligevel
har tænkt sig at forlade virksomheden.

```{r}
tibble(
  "precision" =
    precision(prediction_glm, Churn, .pred_class) %>% 
    select(.estimate),
  "recall" =
    recall(prediction_glm, Churn, .pred_class) %>% 
    select(.estimate)
) %>% 
  unnest() %>% 
  kable()
```

Den anden og sidste populær måleværktøj er F1_score, som er det harmoniske gennemsnit
af precision og recall.  Den perfekte score på 1 fås når precision og recall er perfekte.

```{r}
prediction_glm %>%
  f_meas(Churn, .pred_class) %>%
  select(-.estimator) %>%
  kable()
```

## Fra logitstik regression til Random Forest

Det er utrolig simpel at skifte ens model ud med en anden. Den tidligere
anvendte logistisk regressions model kan vi hurtig skifte ud med en **Random
Forest** model med `ranger`.

## Croos validation sæt op

For at styke modellens prediktive kræft kan man foretage cross validation, som
tit bliver sat op med 10 folder. Det kan implementeres med `vfold_cv()` fra `rsample`,
som splitter det initale trænings data.

```{r}
set.seed(123)
cross_val_tbl <- 
   vfold_cv(train_tbl, v = 10)
```

Vi kan genkende de 5626 fra vores tærningssæt. I hver runde vil 563 observationer
blive brugt til validere modellen for det specifikke fold.

For at ikke blive forvirret over bruget af initial træsning/test split til det
man bruger i cross validation benytter man begreberne `analysis` (estimer modellen)
og `assessment` (valider estimater).

## Opdater recipe

For at bruge Random Forest skal alle numeriske værdier være centred og scaled
og alle faktor skal være dummies.

```{r}
split <- initial_split(telco, prop = 0.8)
train_data <- training(split)
test_data <- testing(split)
```

For at skifte over til en anden model er utroligt simepel. Her ændre vi til
random forest i typen af modellen og tilføjer dens hyperparameter. 

For at gøre processen lidt hurtigere propper jeg det hele i en funktion, som 
estimer modellen på tværs af alle folder og retuner det i en tibble. Desuden skal
der tilføjes et skridt mere for at vi mapper de forskellige folder.

```{r}
recipe_rf <- function(dataset) {
  recipe(Churn ~ ., data = dataset) %>%
    step_string2factor(all_nominal(), -all_outcomes()) %>%
    step_dummy(all_nominal(), -all_outcomes()) %>%
    step_center(all_numeric()) %>%
    step_scale(all_numeric()) %>%
    prep(data = dataset)
}

rf_fun <- function(split, id, try, tree) {
   
  analysis_set <- split %>% analysis()
  analysis_prepped <- analysis_set %>% recipe_rf()
  analysis_baked <- analysis_prepped %>% bake(new_data = analysis_set)
  model_rf <-
    rand_forest(
      mode = "classification",
      mtry = try,
      trees = tree
    ) %>%
    set_engine("ranger",
      importance = "impurity"
    ) %>%
    fit(Churn ~ ., data = analysis_baked)
  assessment_set <- split %>% assessment()
  assessment_prepped <- assessment_set %>% recipe_rf()
  assessment_baked <- assessment_prepped %>% bake(new_data = assessment_set)
  tibble(
    "id" = id,
    "truth" = assessment_baked$Churn,
    "prediction" = model_rf %>%
      predict(new_data = assessment_baked) %>%
      unlist()
  )
  
}

pred_rf <- map2_df(
  .x = cross_val_tbl$splits,
  .y = cross_val_tbl$id,
  ~ rf_fun(split = .x, id = .y, try = 3, tree = 200)
)
head(pred_rf)  

pred_rf %>%
  conf_mat(truth, prediction) %>%
  summary() %>%
  select(-.estimator) %>%
  filter(.metric %in%
    c("accuracy", "precision", "recall", "f_meas")) %>%
  kable()
```

Der er mange matricer til at validere vores model, men vi bruger dem som vi brugte
ved vores logistisk regression. 

Modellen klare sig på lige fod med regressionsmodellen. Man kunne gå tilbage til modellen
og laver yderligere feature eengierning da det ville gøre noget for selve 
præsentationen af modellen.
